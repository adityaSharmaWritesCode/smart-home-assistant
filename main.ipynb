{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f2a0fd1",
   "metadata": {},
   "source": [
    "<h2>Problem Statement : \n",
    "\n",
    "Make a Smart Home Assistant, similar to Alexa, which will be capable of turning on and off lights based on the voice commands given by the user. This will be handled by an LLM gathering voice inputs, and using langgraph to ensure the network structure of the house.\n",
    "<br>#PART 1 : \"What should I wear today?\"\n",
    "\n",
    "\n",
    "<br>#PART 2 : Full Smart home\n",
    "\n",
    "\n",
    "</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37da6d31",
   "metadata": {},
   "source": [
    "<h3>Python playbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea8cde9",
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = \"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\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252b0dd6",
   "metadata": {},
   "source": [
    "<h4> 1. Figuring out how to make speech-to-text work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69aaf19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python program to translate\n",
    "# speech to text and text to speech\n",
    "\n",
    "\n",
    "import speech_recognition as sr\n",
    "import pyttsx3 \n",
    "\n",
    "# Initialize the recognizer \n",
    "r = sr.Recognizer() \n",
    "\n",
    "# Function to convert text to speech\n",
    "def SpeakText(command):\n",
    "    \n",
    "    # Initialize the engine\n",
    "    engine = pyttsx3.init()\n",
    "    engine.say(command) \n",
    "    engine.runAndWait()\n",
    "    \n",
    "    \n",
    "# Loop infinitely for user to speak\n",
    "\n",
    "# while(1):    \n",
    "#     try:\n",
    "        \n",
    "#         # use the microphone as source for input.\n",
    "#         with sr.Microphone() as source2:\n",
    "            \n",
    "#             # wait for a second to let the recognizer adjust the energy threshold based on the surrounding noise level \n",
    "#             r.adjust_for_ambient_noise(source2, duration=0.2)\n",
    "            \n",
    "#             #listens for the user's input \n",
    "#             audio2 = r.listen(source2)\n",
    "            \n",
    "#             # Using google to recognize audio\n",
    "#             MyText = r.recognize_google(audio2)\n",
    "#             MyText = MyText.lower()\n",
    "\n",
    "#             print(\"Did you say \", MyText)\n",
    "#             SpeakText(MyText)\n",
    "            \n",
    "#     except sr.RequestError as e:\n",
    "#         print(\"Could not request results; {0}\".format(e))\n",
    "        \n",
    "#     except sr.UnknownValueError:\n",
    "#         print(\"unknown error occurred\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069fb7e0",
   "metadata": {},
   "source": [
    "<h4>2. That was surprisingly quick. Now lets make an agent. </h4>\n",
    "<p>The main thing I want to do right now is build a really simple agent, which only has the \"Start\", \"Agent\" and \"Output\" state. The Agent will take in the user's input as speech, and give its own response in an audio output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa09590",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, List\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langgraph.graph import START, END, StateGraph\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    messages: List[HumanMessage]\n",
    "\n",
    "llm = ChatOllama(model=\"qwen2.5:0.5b\")\n",
    "\n",
    "def process_node(state: AgentState) -> AgentState:\n",
    "    \"\"\"This node simply sends the user input as a human message to chat ollama llm, and prints its response without recording it in the state\"\"\"\n",
    "    response = llm.invoke(state[\"messages\"])\n",
    "    print(\"\\nAI: \" + response.content)\n",
    "    return state\n",
    "\n",
    "graph = StateGraph(AgentState)\n",
    "graph.add_node(\"Agent\", process_node)\n",
    "graph.add_edge(START, \"Agent\")\n",
    "graph.add_edge(\"Agent\", END)\n",
    "\n",
    "app = graph.compile()\n",
    "from IPython.display import Image, display\n",
    "display(Image(app.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc454f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation_history = []\n",
    "\n",
    "def get_voice_input():\n",
    "    try:\n",
    "        \n",
    "        # use the microphone as source for input.\n",
    "        with sr.Microphone() as source2:\n",
    "            \n",
    "            # wait for a second to let the recognizer adjust the energy threshold based on the surrounding noise level \n",
    "            r.adjust_for_ambient_noise(source2, duration=0.2)\n",
    "            \n",
    "            #listens for the user's input \n",
    "            audio2 = r.listen(source2)\n",
    "            \n",
    "            # Using google to recognize audio\n",
    "            user_input = r.recognize_google(audio2)\n",
    "            user_input = user_input.lower()\n",
    "            \n",
    "    except sr.RequestError as e:\n",
    "        print(\"Could not request results; {0}\".format())\n",
    "        \n",
    "    except sr.UnknownValueError:\n",
    "        print(\"unknown error occurred\")\n",
    "\n",
    "    return user_input\n",
    "\n",
    "command =  get_voice_input()\n",
    "\n",
    "while command != 'exit game':\n",
    "     \n",
    "        print(\"Human: \", command)\n",
    "        conversation_history.append(HumanMessage(content=command))\n",
    "        AiResponse = app.invoke({\"messages\": conversation_history})\n",
    "        conversation_history = AiResponse[\"messages\"]\n",
    "        print(f\"{AiResponse[\"messages\"]}\")\n",
    "        #SpeakText(AiResponse)\n",
    "        command = get_voice_input()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2553e574",
   "metadata": {},
   "source": [
    "Now lets start to work on making our graph a little more complicated. I am thinking of making a room builder node (setup) and a tool node which turns lights on and off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76627dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_core.tools import tool\n",
    "\n",
    "# @tool\n",
    "# def house_builder(house : map[map]) -> map[map]:\n",
    "#     \"\"\"\n",
    "#     This function updates the house based on the current input text\n",
    "#     \"\"\"\n",
    "#     house.\n",
    "# def setup_node(state : AgentState)-> AgentState:\n",
    "#     \"\"\"This function is used to ask user for their input on how life works\"\"\"\n",
    "\n",
    "#     return state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b0c9ff",
   "metadata": {},
   "source": [
    "<h2>#PART 2 : Full Smart home"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478aa251",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END, START\n",
    "from langchain_ollama.chat_models import ChatOllama\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from typing import TypedDict, Dict, List, Union\n",
    "from langchain_core.tools import tool\n",
    "import re\n",
    "\n",
    "# -------------------------------\n",
    "# STATE\n",
    "# -------------------------------\n",
    "\n",
    "class HomeState(TypedDict):\n",
    "    messages: List[Union[HumanMessage, AIMessage]]\n",
    "#    home_config: Dict[str, Dict[str, str]]  # room -> {device -> state}\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# LLM Node: ChatOllama\n",
    "# -------------------------------\n",
    "\n",
    "llm = ChatOllama(model=\"qwen3\")\n",
    "\n",
    "home_config = {}\n",
    "\n",
    "def agent_node(state: HomeState) -> HomeState:\n",
    "    \"\"\"Invoke the local LLM to generate a response based on current message history.\"\"\"\n",
    "    response = llm.invoke(state[\"messages\"])\n",
    "    return {\"messages\": state[\"messages\"] + [response], \"home_config\": state[\"home_config\"]}\n",
    "\n",
    "# -------------------------------\n",
    "# Setup Node: Build home configuration\n",
    "# -------------------------------\n",
    "@tool\n",
    "def setup_node(state: HomeState) -> HomeState:\n",
    "    \"\"\"\n",
    "    Parse the user's input to initialize room-device configuration.\n",
    "\n",
    "    Extracts device types and quantities (e.g., '3 lights in the living room') \n",
    "    and stores them in a nested map with each device initialized to OFF.\n",
    "    \"\"\"\n",
    "    last_msg = state[\"messages\"][-1]\n",
    "    if not isinstance(last_msg, HumanMessage):\n",
    "        return state\n",
    "\n",
    "    text = last_msg.content.lower()\n",
    "    room_config = {}\n",
    "    if any(x in text for x in {\"light\", \"lights\", \"AC\", \"ACs\", \"fan\", \"fans\",\"TV\", \"TVs\", \"speaker\", \"speakers\"}):\n",
    "        #if \"living_room\" not in state[\"home_config\"]:\n",
    "        if \"living_room\" not in home_config:    \n",
    "            #state[\"home_config\"][\"living_room\"] = {}\n",
    "            home_config[\"living_room\"] = {}\n",
    "\n",
    "        for i in range(1, 10):\n",
    "            device_name = f\"{x}{i}\" \n",
    "            #if device_name not in state[\"home_config\"][\"living_room\"]:\n",
    "            #    state[\"home_config\"][\"living_room\"][device_name] = \"OFF\"\n",
    "            if device_name not in home_config[\"living_room\"]:\n",
    "                home_config[\"living_room\"][device_name] = \"OFF\"\n",
    "            else:\n",
    "                continue\n",
    "    # match = re.findall(r'(\\d+)\\s+(lights?|fans?|acs?)\\s+in\\s+the\\s+([\\w\\s]+)', text)\n",
    "\n",
    "    # for count_str, device_type, room in match:\n",
    "    #     count = int(count_str)\n",
    "    #     room = room.strip()\n",
    "    #     room_key = room.lower()\n",
    "    #     if room_key not in state[\"home_config\"]:\n",
    "    #         state[\"home_config\"][room_key] = {}\n",
    "\n",
    "    #     for i in range(1, count + 1):\n",
    "    #         device_name = f\"{device_type.rstrip('s')}{i}\"\n",
    "    #         state[\"home_config\"][room_key][device_name] = \"OFF\"\n",
    "\n",
    "    return state\n",
    "\n",
    "# -------------------------------\n",
    "# Operation Node: Turn devices ON/OFF\n",
    "# -------------------------------\n",
    "\n",
    "@tool\n",
    "def operation_node(state: HomeState) -> HomeState:\n",
    "    \"\"\"\n",
    "    Modify the ON/OFF status of devices in specific rooms based on user input.\n",
    "\n",
    "    Identifies the room and device types mentioned in the message and updates \n",
    "    their power state accordingly within the stored home configuration.\n",
    "    \"\"\"\n",
    "    last_msg = state[\"messages\"][-1]\n",
    "    if not isinstance(last_msg, HumanMessage):\n",
    "        return state\n",
    "\n",
    "    text = last_msg.content.lower()\n",
    "    #room_keys = list(state[\"home_config\"].keys())\n",
    "    room_keys = home_config.keys()\n",
    "    for room in room_keys:\n",
    "        if room in text:\n",
    "            for device in list(state[\"home_config\"][room].keys()):\n",
    "                if device.startswith(\"light\") and \"light\" in text:\n",
    "                    if \"on\" in text:\n",
    "                        home_config[room][device] = \"ON\"\n",
    "                    elif \"off\" in text:\n",
    "                        home_config[room][device] = \"OFF\"\n",
    "                elif device.startswith(\"fan\") and \"fan\" in text:\n",
    "                    if \"on\" in text:\n",
    "                        home_config[room][device] = \"ON\"\n",
    "                    elif \"off\" in text:\n",
    "                        home_config[room][device] = \"OFF\"\n",
    "                elif device.startswith(\"ac\") and \"ac\" in text:\n",
    "                    if \"on\" in text:\n",
    "                        home_config[room][device] = \"ON\"\n",
    "                    elif \"off\" in text:\n",
    "                        home_config[room][device] = \"OFF\"\n",
    "    return state\n",
    "\n",
    "# -------------------------------\n",
    "# Router Node: Decide next step\n",
    "# -------------------------------\n",
    "\n",
    "def router_node(state: HomeState) -> str:\n",
    "    last_msg = state[\"messages\"][-1]\n",
    "    if not isinstance(last_msg, HumanMessage):\n",
    "        return \"END\"\n",
    "\n",
    "    text = last_msg.content.lower()\n",
    "    if \"i have\" in text or \"there are\" in text:\n",
    "        return \"SETUP\"\n",
    "    elif \"turn on\" in text or \"turn off\" in text:\n",
    "        return \"OPERATE\"\n",
    "    else:\n",
    "        return \"END\"\n",
    "\n",
    "# -------------------------------\n",
    "# Graph Definition\n",
    "# -------------------------------\n",
    "\n",
    "graph = StateGraph(HomeState)\n",
    "\n",
    "graph.add_node(\"AGENT\", agent_node)\n",
    "graph.add_node(\"SETUP\", setup_node)\n",
    "graph.add_node(\"OPERATE\", operation_node)\n",
    "\n",
    "\n",
    "# Transitions\n",
    "graph.add_edge(START, \"AGENT\")\n",
    "graph.add_conditional_edges(\"AGENT\", router_node, {\n",
    "    \"SETUP\": \"SETUP\",\n",
    "    \"OPERATE\": \"OPERATE\",\n",
    "    \"END\": END\n",
    "})\n",
    "graph.add_edge(\"SETUP\", \"AGENT\")\n",
    "graph.add_edge(\"OPERATE\", \"AGENT\")\n",
    "\n",
    "\n",
    "app = graph.compile()\n",
    "\n",
    "\n",
    "from IPython.display import Image, display\n",
    "display(Image(app.get_graph().draw_mermaid_png()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0ba62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# Run Loop\n",
    "# -------------------------------\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    state: HomeState = {\n",
    "        \"messages\": []\n",
    "    }\n",
    "\n",
    "home_config = {}\n",
    "\n",
    "    while True:\n",
    "        user_input = input(\"You: \")\n",
    "        if user_input.lower() in [\"exit\", \"quit\"]:\n",
    "            break\n",
    "\n",
    "        state[\"messages\"].append(HumanMessage(content=user_input))\n",
    "        state = app.invoke(state)\n",
    "        print(state)\n",
    "        print(\"\\nUpdated Home Configuration:\")\n",
    "        for room, devices in state[\"home_config\"].items():\n",
    "            print(f\"{room.title()}:\")\n",
    "            for device, status in devices.items():\n",
    "                print(f\"  {device}: {status}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a724b7",
   "metadata": {},
   "source": [
    "Doesn't seem to be working well, hmm, I know, lets get an Open AI model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50275f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import Runnable, RunnableConfig\n",
    "from langchain_openai import ChatOpenAI\n",
    "from datetime import datetime\n",
    "\n",
    "primary_assistant_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful smart home assistant.\"\n",
    "            \"You help the user control the electronics in each room of their house\"\n",
    "            \" Use the provided tools to create an internal configuration of what the user's house looks like, and also keep a track of which devices are on and off. \"\n",
    "            \" When searching, be persistent. Expand your query bounds if the first search returns no results. \"\n",
    "            \" If a search comes up empty, expand your search before giving up.\"\n",
    "            \"\\n\\nCurrent house structure:\\n<User>\\n{home_config}\\n</User>\"\n",
    "            \"\\nCurrent time: {time}.\",\n",
    "        ),\n",
    "        (\"placeholder\", \"{messages}\"),\n",
    "    ]\n",
    ").partial(time=datetime.now)\n",
    "\n",
    "tools = [\n",
    "    setup_node,\n",
    "    operation_node\n",
    "]\n",
    "\n",
    "llm_openai = primary_assistant_prompt | ChatOpenAI(\n",
    "    llm = \"gpt-4o-mini\",\n",
    "    timeout=None,\n",
    "    temperature=0,\n",
    "    api_key= API_KEY\n",
    ").bind_tools(tools)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9385c555",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "def new_agent_node(state: HomeState) -> HomeState:\n",
    "    \"\"\"Invoke the local LLM to generate a response based on current message history.\"\"\"\n",
    "    response = llm_openai.invoke(state[\"messages\"])\n",
    "    return {\"messages\": state[\"messages\"] + [response]}\n",
    "\n",
    "\n",
    "builder = StateGraph(HomeState)\n",
    "\n",
    "builder.add_node(\"AGENT\", new_agent_node)\n",
    "builder.add_node(\"SETUP\", setup_node)\n",
    "builder.add_node(\"OPERATE\", operation_node)\n",
    "\n",
    "\n",
    "# Transitions\n",
    "builder.add_edge(START, \"AGENT\")\n",
    "builder.add_conditional_edges(\"AGENT\", router_node, {\n",
    "    \"SETUP\": \"SETUP\",\n",
    "    \"OPERATE\": \"OPERATE\",\n",
    "    \"END\": END\n",
    "})\n",
    "builder.add_edge(\"SETUP\", \"AGENT\")\n",
    "builder.add_edge(\"OPERATE\", \"AGENT\")\n",
    "\n",
    "# memory = MemorySaver()\n",
    "# test_app = builder.compile(checkpointer=memory)\n",
    "\n",
    "test_app = builder.compile()\n",
    "\n",
    "from IPython.display import Image, display\n",
    "display(Image(test_app.get_graph().draw_mermaid_png()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "94c238a6",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Completions.create() got an unexpected keyword argument 'llm'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# config = {\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m#     \"configurable\": {\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m#         \"thread_id\": thread_id,\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m#     }\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# }\u001b[39;00m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m question \u001b[38;5;129;01min\u001b[39;00m test_questions:\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m     response = \u001b[43mtest_app\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# config,\u001b[39;49;00m\n\u001b[32m     21\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     22\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     23\u001b[39m     \u001b[38;5;28mprint\u001b[39m(response)\n\u001b[32m     24\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mUpdated home configuration : \u001b[39m\u001b[33m\"\u001b[39m, home_config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\langgraph\\pregel\\__init__.py:2894\u001b[39m, in \u001b[36mPregel.invoke\u001b[39m\u001b[34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, **kwargs)\u001b[39m\n\u001b[32m   2891\u001b[39m chunks: \u001b[38;5;28mlist\u001b[39m[Union[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any], Any]] = []\n\u001b[32m   2892\u001b[39m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] = []\n\u001b[32m-> \u001b[39m\u001b[32m2894\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2895\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2896\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2897\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2898\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2899\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2900\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2901\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcheckpoint_during\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcheckpoint_during\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2902\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdebug\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdebug\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2903\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2904\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2905\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[32m   2906\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2907\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   2908\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mints\u001b[49m\u001b[43m \u001b[49m\u001b[43m:=\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mINTERRUPT\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[32m   2909\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\langgraph\\pregel\\__init__.py:2527\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, subgraphs)\u001b[39m\n\u001b[32m   2525\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m loop.match_cached_writes():\n\u001b[32m   2526\u001b[39m             loop.output_writes(task.id, task.writes, cached=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m2527\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2528\u001b[39m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrites\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2529\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2530\u001b[39m \u001b[43m            \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2531\u001b[39m \u001b[43m            \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43maccept_push\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2532\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2533\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[32m   2534\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2535\u001b[39m \u001b[38;5;66;03m# emit output\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\langgraph\\pregel\\runner.py:157\u001b[39m, in \u001b[36mPregelRunner.tick\u001b[39m\u001b[34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[39m\n\u001b[32m    155\u001b[39m t = tasks[\u001b[32m0\u001b[39m]\n\u001b[32m    156\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m157\u001b[39m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    158\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    159\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    160\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    162\u001b[39m \u001b[43m                \u001b[49m\u001b[43m_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[43m                \u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[43m                \u001b[49m\u001b[43mretry\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    166\u001b[39m \u001b[43m                \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    167\u001b[39m \u001b[43m                \u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m                \u001b[49m\u001b[43mreraise\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreraise\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    172\u001b[39m     \u001b[38;5;28mself\u001b[39m.commit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    173\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\langgraph\\pregel\\retry.py:40\u001b[39m, in \u001b[36mrun_with_retry\u001b[39m\u001b[34m(task, retry_policy, configurable)\u001b[39m\n\u001b[32m     38\u001b[39m     task.writes.clear()\n\u001b[32m     39\u001b[39m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mproc\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     42\u001b[39m     ns: \u001b[38;5;28mstr\u001b[39m = config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\langgraph\\utils\\runnable.py:623\u001b[39m, in \u001b[36mRunnableSeq.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    621\u001b[39m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[32m    622\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m--> \u001b[39m\u001b[32m623\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    624\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    625\u001b[39m     \u001b[38;5;28minput\u001b[39m = step.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\langgraph\\utils\\runnable.py:377\u001b[39m, in \u001b[36mRunnableCallable.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    375\u001b[39m         run_manager.on_chain_end(ret)\n\u001b[32m    376\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m377\u001b[39m     ret = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    378\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.recurse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable):\n\u001b[32m    379\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ret.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 5\u001b[39m, in \u001b[36mnew_agent_node\u001b[39m\u001b[34m(state)\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mnew_agent_node\u001b[39m(state: HomeState) -> HomeState:\n\u001b[32m      4\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Invoke the local LLM to generate a response based on current message history.\"\"\"\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m     response = \u001b[43mllm_openai\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m: state[\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m] + [response]}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\langchain_core\\runnables\\base.py:3047\u001b[39m, in \u001b[36mRunnableSequence.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   3045\u001b[39m                 input_ = context.run(step.invoke, input_, config, **kwargs)\n\u001b[32m   3046\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3047\u001b[39m                 input_ = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3048\u001b[39m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[32m   3049\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\langchain_core\\runnables\\base.py:5431\u001b[39m, in \u001b[36mRunnableBindingBase.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   5424\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   5425\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m   5426\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   5429\u001b[39m     **kwargs: Optional[Any],\n\u001b[32m   5430\u001b[39m ) -> Output:\n\u001b[32m-> \u001b[39m\u001b[32m5431\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbound\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5432\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   5433\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_merge_configs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5434\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m{\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5435\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\langchain_core\\language_models\\chat_models.py:372\u001b[39m, in \u001b[36mBaseChatModel.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    360\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    361\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    362\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    367\u001b[39m     **kwargs: Any,\n\u001b[32m    368\u001b[39m ) -> BaseMessage:\n\u001b[32m    369\u001b[39m     config = ensure_config(config)\n\u001b[32m    370\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    371\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mChatGeneration\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m--> \u001b[39m\u001b[32m372\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    373\u001b[39m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    374\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    375\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    376\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    377\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    378\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    379\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    380\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    381\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m.generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m    382\u001b[39m     ).message\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\langchain_core\\language_models\\chat_models.py:957\u001b[39m, in \u001b[36mBaseChatModel.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m    948\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    949\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m    950\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    954\u001b[39m     **kwargs: Any,\n\u001b[32m    955\u001b[39m ) -> LLMResult:\n\u001b[32m    956\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m--> \u001b[39m\u001b[32m957\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\langchain_core\\language_models\\chat_models.py:776\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    773\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[32m    774\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    775\u001b[39m         results.append(\n\u001b[32m--> \u001b[39m\u001b[32m776\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    777\u001b[39m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    778\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    779\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    780\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    781\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    782\u001b[39m         )\n\u001b[32m    783\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    784\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\langchain_core\\language_models\\chat_models.py:1022\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1020\u001b[39m     result = generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[32m   1021\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._generate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1022\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1023\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1024\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1025\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1026\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._generate(messages, stop=stop, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\langchain_openai\\chat_models\\base.py:995\u001b[39m, in \u001b[36mBaseChatOpenAI._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m    993\u001b[39m     generation_info = {\u001b[33m\"\u001b[39m\u001b[33mheaders\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mdict\u001b[39m(raw_response.headers)}\n\u001b[32m    994\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m995\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mpayload\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    996\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._create_chat_result(response, generation_info)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\openai\\_utils\\_utils.py:287\u001b[39m, in \u001b[36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    285\u001b[39m             msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[32m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    286\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[32m--> \u001b[39m\u001b[32m287\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mTypeError\u001b[39m: Completions.create() got an unexpected keyword argument 'llm'",
      "During task with name 'AGENT' and id 'b85c20bc-fe25-e8bf-78ae-9ca237b30a0e'"
     ]
    }
   ],
   "source": [
    "import uuid\n",
    "\n",
    "test_questions = [\n",
    "    \"Hi there, Can you help me setup my house information?\",\n",
    "    \"I have 3 lights in my living room, and 1 AC. I also have 1 light in my bedroom and 1 fan.\"\n",
    "    \"Can you turn one of the lights in the living room on?\",\n",
    "]\n",
    "\n",
    "thread_id = str(uuid.uuid4())\n",
    "\n",
    "# config = {\n",
    "#     \"configurable\": {\n",
    "#         \"thread_id\": thread_id,\n",
    "#     }\n",
    "# }\n",
    "\n",
    "for question in test_questions:\n",
    "    response = test_app.invoke(\n",
    "        {\"messages\" : (\"user\", question)},\n",
    "        # config,\n",
    "        stream_mode=\"values\"\n",
    "    )\n",
    "    print(response)\n",
    "    print(\"Updated home configuration : \", home_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b96cf1f",
   "metadata": {},
   "source": [
    "Never mind, let me start from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0a82142",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Annotated, Sequence, Optional, Dict\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langgraph.graph import START, END, StateGraph\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.messages import HumanMessage, AIMessage, BaseMessage, SystemMessage, ToolMessage\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.graph.message import add_messages # a reducer function which allows merging all data into the state efficiently. If we dont use this reducer function, the updates may replace the existing value entirely!\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], add_messages]\n",
    "#    config_map : Dict[str, Dict[str, str]]\n",
    "\n",
    "operation = [\"OFF\", \"ON\"]\n",
    "\n",
    "@tool\n",
    "def home_setup(room_key: Optional[str], device_key: Optional[str], config_map: Dict[str, Dict[str, str]]):\n",
    "    \"\"\"This tool takes the current home configuration and the room key and device key as input, and adds the room key to the home configuration\"\"\"\n",
    "    print(config_map)\n",
    "    if room_key:\n",
    "        if room_key not in config_map:\n",
    "            config_map[room_key] = {}\n",
    "\n",
    "        if device_key:\n",
    "            if device_key not in config_map[room_key]:\n",
    "                config_map[room_key][device_key] = operation[0]\n",
    "                return f\"The device with ID {device_key} has been succesfully added to the room {room_key} in our home!\\n\"\n",
    "        else:\n",
    "            return f\"The room with ID {room_key} has been succesfully addded to our home!\\n\"\n",
    "    return \"Invalid input. Try again.\\n\"\n",
    "\n",
    "\n",
    "@tool\n",
    "def home_operation(room_key: str, device_key: str, config_map: Dict[str, Dict[str, str]]):\n",
    "    \"\"\"This tool takes the already specified room key and device key and the home configuration map as input, and switches the specified device key \"\"\"\n",
    "    print(config_map)\n",
    "    if room_key not in config_map:\n",
    "        return \"Invalid input. Room does not exist\"\n",
    "    \n",
    "    if device_key not in config_map[room_key]:\n",
    "        return \"Invalid input. This device has not been set up in this room\"\n",
    "    \n",
    "    last_operation = operation[0]\n",
    "    if config_map[room_key][device_key] == operation[0]:\n",
    "        config_map[room_key][device_key] = operation[1]\n",
    "        last_operation = operation[1]\n",
    "    else:\n",
    "        config_map[room_key][device_key] = operation[0]\n",
    "\n",
    "    return f\"The device \\\"{device_key}\\\" in room \\\"{room_key}\\\" has been turned {last_operation}.\\n\" \n",
    "\n",
    "good_boy_tools = [\n",
    "    home_setup,\n",
    "    home_operation\n",
    "]\n",
    "\n",
    "good_boy_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful smart home assistant.\"\n",
    "            \"You help the user control the electronics in each room of their house\"\n",
    "            \" Use the provided tools to create an internal configuration of what the user's house looks like, and also keep a track of which devices are on and off. \"\n",
    "            \" When searching, be persistent. Expand your query bounds if the first search returns no results. \"\n",
    "            \" If a search comes up empty, expand your search before giving up.\"\n",
    "            \"\\n\\nCurrent house structure:\\n<User>\\n{home_config}\\n</User>\"\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model = good_boy_prompt | ChatOllama(model=\"qwen3\", temperature=0).bind_tools(good_boy_tools)\n",
    "\n",
    "# NODES -\n",
    "\n",
    "good_boy_home_config = {}\n",
    "\n",
    "def call_llm(state: State) -> State:\n",
    "    \"\"\"This function invokes the llm and gives it basic context\"\"\"\n",
    "    response = model.invoke(state[\"messages\"])\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "def should_continue(state: State):\n",
    "    \"\"\"This function decides if the agent should call a tool or if it should terminate the program\"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    lastMessage = messages[-1]\n",
    "    if not lastMessage.tool_calls:\n",
    "        return \"exit\"\n",
    "    else:\n",
    "        return \"continue\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2839e2eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "    \n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "#GRAPH SETUP\n",
    "good_boy_graph = StateGraph(State)\n",
    "\n",
    "good_boy_graph.add_node(\"Thinker\", call_llm)\n",
    "good_boy_graph.add_node(\"Doer\", ToolNode(tools=good_boy_tools))\n",
    "\n",
    "good_boy_graph.add_edge(START, \"Thinker\")\n",
    "good_boy_graph.add_conditional_edges(\n",
    "    \"Thinker\",\n",
    "    should_continue,\n",
    "    {\n",
    "        \"exit\": END,\n",
    "        \"continue\": \"Doer\"\n",
    "    }\n",
    ")\n",
    "\n",
    "good_boy_graph.add_edge(\"Doer\", \"Thinker\")\n",
    "\n",
    "good_boy_app = good_boy_graph.compile()\n",
    "\n",
    "from IPython.display import Image, display\n",
    "display(Image(good_boy_app.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbbdd04e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hi, I have a living room with 1 light and 1 AC. Can you turn the AC on for me?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  home_setup (1bd2029f-d564-4541-8de7-f653ff3208fd)\n",
      " Call ID: 1bd2029f-d564-4541-8de7-f653ff3208fd\n",
      "  Args:\n",
      "    config_map: {'living_room': {'AC': {'state': 'off'}, 'light': {'state': 'off'}}}\n",
      "    device_key: AC\n",
      "    room_key: living_room\n",
      "  home_operation (20316490-18ea-45ca-b4f2-d30fcb981f4a)\n",
      " Call ID: 20316490-18ea-45ca-b4f2-d30fcb981f4a\n",
      "  Args:\n",
      "    config_map: {'living_room': {'AC': {'state': 'off'}, 'light': {'state': 'off'}}}\n",
      "    device_key: AC\n",
      "    room_key: living_room\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: home_operation\n",
      "\n",
      "Error: 2 validation errors for home_operation\n",
      "config_map.living_room.AC\n",
      "  Input should be a valid string [type=string_type, input_value={'state': 'off'}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.11/v/string_type\n",
      "config_map.living_room.light\n",
      "  Input should be a valid string [type=string_type, input_value={'state': 'off'}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.11/v/string_type\n",
      " Please fix your mistakes.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  home_setup (fab5198d-9de4-4065-b286-1e0e3bb48e1e)\n",
      " Call ID: fab5198d-9de4-4065-b286-1e0e3bb48e1e\n",
      "  Args:\n",
      "    config_map: {'living_room': {'AC': 'off', 'light': 'off'}}\n",
      "    device_key: AC\n",
      "    room_key: living_room\n",
      "  home_operation (c23dc903-66f6-488c-a95b-46593191a3b2)\n",
      " Call ID: c23dc903-66f6-488c-a95b-46593191a3b2\n",
      "  Args:\n",
      "    config_map: {'living_room': {'AC': 'on', 'light': 'off'}}\n",
      "    device_key: AC\n",
      "    room_key: living_room\n",
      "{'living_room': {'AC': 'off', 'light': 'off'}}\n",
      "{'living_room': {'AC': 'on', 'light': 'off'}}\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: home_operation\n",
      "\n",
      "The device \"AC\" in room \"living_room\" has been turned OFF.\n",
      "\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  home_operation (1103c485-c6b8-44af-87f9-47684de47da6)\n",
      " Call ID: 1103c485-c6b8-44af-87f9-47684de47da6\n",
      "  Args:\n",
      "    config_map: {'living_room': {'AC': 'on', 'light': 'off'}}\n",
      "    device_key: AC\n",
      "    room_key: living_room\n",
      "{'living_room': {'AC': 'on', 'light': 'off'}}\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: home_operation\n",
      "\n",
      "The device \"AC\" in room \"living_room\" has been turned OFF.\n",
      "\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  home_operation (3c58abfc-8b8e-4170-bc88-bba40107c14c)\n",
      " Call ID: 3c58abfc-8b8e-4170-bc88-bba40107c14c\n",
      "  Args:\n",
      "    config_map: {'living_room': {'AC': 'on', 'light': 'off'}}\n",
      "    device_key: AC\n",
      "    room_key: living_room\n",
      "{'living_room': {'AC': 'on', 'light': 'off'}}\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: home_operation\n",
      "\n",
      "The device \"AC\" in room \"living_room\" has been turned OFF.\n",
      "\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  home_operation (a100a65c-524b-4539-bf28-b658519e6102)\n",
      " Call ID: a100a65c-524b-4539-bf28-b658519e6102\n",
      "  Args:\n",
      "    config_map: {'living_room': {'AC': 'on', 'light': 'off'}}\n",
      "    device_key: AC\n",
      "    room_key: living_room\n",
      "{'living_room': {'AC': 'on', 'light': 'off'}}\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: home_operation\n",
      "\n",
      "The device \"AC\" in room \"living_room\" has been turned OFF.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def print_messages(messages):\n",
    "    \"\"\"Function made to print the messages in a more readable format\"\"\"\n",
    "    if not messages:\n",
    "        return\n",
    "    \n",
    "    for message in messages[-3:]:\n",
    "        if isinstance(message, ToolMessage):\n",
    "            print(f\"\\nTOOL RESULT: {message.content}\")\n",
    "\n",
    "def print_stream(stream):\n",
    "    for s in stream:\n",
    "        message = s[\"messages\"][-1]\n",
    "        if isinstance(message, tuple):\n",
    "            print(message)\n",
    "        else:\n",
    "            message.pretty_print()\n",
    "\n",
    "inputs = {\"messages\": [(\"user\", \"Hi, I have a living room with 1 light and 1 AC. Can you turn the AC on for me?\")]}\n",
    "print_stream(good_boy_app.stream(inputs, stream_mode=\"values\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6adb9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
